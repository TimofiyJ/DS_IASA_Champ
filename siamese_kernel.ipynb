{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a650f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications, losses, optimizers, metrics, Model\n",
    "from tensorflow.keras.layers import Layer, Input, Dense, Flatten, Lambda, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16, vgg16\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213aaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio to resize to with cv2.resize(), needs to be (270, 480) if resizing is done with tf.keras.preprocessing.image.load_img()\n",
    "IMG_SIZE = (224, 224) \n",
    "\n",
    "# number of directories used for benign anchor/positive images because we don't need thousands of them\n",
    "DIR_SIZE = 21\n",
    "\n",
    "# limit for the number of images read per directory to prevent OOM\n",
    "COUNT_PER_DIR = 300\n",
    "\n",
    "# limit for the number of triplets to read per triplet category to prevent OOM\n",
    "NUM_TRIPLETS = 300\n",
    "\n",
    "# number of epochs to run per training iteration\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d444d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "\n",
    "    # training images, labels, and unique labels\n",
    "    images_train = np.array([])\n",
    "    labels_train = np.array([])\n",
    "    unique_train_label = np.array([])\n",
    "\n",
    "    # map cluster labels to training image indices belonging to that cluster\n",
    "    map_train_label_indices = dict()\n",
    "\n",
    "    def __init__(self, data_src, benign_anc_path, benign_pos_path, benign_neg_path):\n",
    "        self.data_src = data_src\n",
    "        \n",
    "        # path to the anchor/positive negative images\n",
    "        self.benign_anc_path = benign_anc_path\n",
    "        self.benign_pos_path = benign_pos_path\n",
    "        self.benign_neg_path = benign_neg_path\n",
    "        \n",
    "        print(\"Loading the Dataset...\")\n",
    "        self.images_train, self.labels_train = self.preprocessing()\n",
    "        self.unique_train_label = np.unique(self.labels_train)\n",
    "        self.map_train_label_indices = {label: np.flatnonzero(self.labels_train == label) for label in\n",
    "                                        self.unique_train_label}\n",
    "        \n",
    "        # starting idxs for benign anchor/pos/neg directories\n",
    "        # needed when getting triplets to locate the respective directories\n",
    "        self.benign_anc_start = len(os.listdir(self.data_src)) # ex. 23 \n",
    "        self.benign_pos_start = self.benign_anc_start + DIR_SIZE # ex. 23 + 500 = 523\n",
    "        self.benign_neg_start = self.benign_pos_start + DIR_SIZE # ex. 523 + 500 = 1023\n",
    "\n",
    "        print('Preprocessing Done. Summary:')\n",
    "        print(\"Images train :\", self.images_train.shape)\n",
    "        print(\"Labels train :\", self.labels_train.shape)\n",
    "        print(\"Unique label :\", self.unique_train_label)\n",
    "\n",
    "    def read_dataset(self):\n",
    "        \n",
    "        # count how many images we are reading prior so that we don't iteratively append to the array \n",
    "        count = 0\n",
    "        directories = os.listdir(self.data_src)\n",
    "        \n",
    "        # without this, the directories will be ordered as such: \"1\", \"100\", \"2\", ...\n",
    "        \n",
    "        # add all counts of images in each of the malicious page screenshot directories\n",
    "        for directory in directories:\n",
    "            count += len([file for file in os.listdir(os.path.join(self.data_src, directory))])\n",
    "\n",
    "        # increment count by 1 per directory since only 1 anchor image is used per directory\n",
    "        benign_anc_dir = os.listdir(self.benign_anc_path)\n",
    "        for b_dir in benign_anc_dir[:DIR_SIZE]:\n",
    "            count += 1\n",
    "\n",
    "        # 30 images are selected per positive directory (could be adjusted per need)\n",
    "        benign_pos_dir = os.listdir(self.benign_pos_path)\n",
    "        for b_dir in benign_pos_dir[:DIR_SIZE]:\n",
    "            count += COUNT_PER_DIR\n",
    "\n",
    "        # all benign images from the single negative directory is read\n",
    "        benign_neg_dir = os.listdir(self.benign_neg_path)\n",
    "        for b_dir in benign_neg_dir:\n",
    "            count += len([file for file in os.listdir(os.path.join(self.benign_neg_path, b_dir))])\n",
    "\n",
    "        X = [None] * count\n",
    "        y = [None] * count\n",
    "        idx = 0\n",
    "\n",
    "        # read malicious images\n",
    "        for directory in directories:\n",
    "            try:\n",
    "                print('Read directory: ', directory)\n",
    "                for pic in os.listdir(os.path.join(self.data_src, directory)):\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(self.data_src, directory, pic),interpolation='bilinear')\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    img = cv2.resize(img, IMG_SIZE)\n",
    "\n",
    "                    X[idx] = preprocess_input(img)                    \n",
    "                    y[idx] = directory\n",
    "                    idx += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Failed to read images from Directory: ', directory)\n",
    "                print('Exception Message: ', e)\n",
    "                \n",
    "        # read benign anchor images\n",
    "        for b_dir in benign_anc_dir[:DIR_SIZE]:\n",
    "            try:\n",
    "                print('Read benign anchor directory: ', b_dir)\n",
    "                for pic in os.listdir(os.path.join(self.benign_anc_path, b_dir)):\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(self.benign_anc_path, b_dir, pic),interpolation='bilinear')\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    img = cv2.resize(img, IMG_SIZE)\n",
    "\n",
    "                    X[idx] = preprocess_input(img)\n",
    "                    # 10,000 offset to prevent labels from overlapping\n",
    "                    y[idx] = int(b_dir) + 10000\n",
    "                    idx += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Failed to read images from Directory: ', directory)\n",
    "                print('Exception Message: ', e)\n",
    "                \n",
    "        # read benign positive images (augmented)\n",
    "        for b_dir in benign_pos_dir[:DIR_SIZE]:\n",
    "            try:\n",
    "                print('Read benign positive directory: ', b_dir)\n",
    "                for pic in os.listdir(os.path.join(self.benign_pos_path, b_dir))[:30]:\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(self.benign_pos_path, b_dir, pic),interpolation='bilinear')\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    img = cv2.resize(img, IMG_SIZE)\n",
    "\n",
    "                    X[idx] = preprocess_input(img)\n",
    "                    # 20,000 offset to prevent labels from overlapping\n",
    "                    y[idx] = int(b_dir) + 20000\n",
    "                    idx += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Failed to read images from Directory: ', directory)\n",
    "                print('Exception Message: ', e)\n",
    "        \n",
    "        # read benign negative images\n",
    "        for b_dir in benign_neg_dir:\n",
    "            try:\n",
    "                print('Read benign negative directory: ', b_dir)\n",
    "                for pic in os.listdir(os.path.join(self.benign_neg_path, b_dir)):\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(self.benign_neg_path, b_dir, pic),interpolation='bilinear')\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    img = cv2.resize(img, IMG_SIZE)\n",
    "\n",
    "                    X[idx] = preprocess_input(img)\n",
    "                    # 30,000 offset to prevent labels from overlapping\n",
    "                    y[idx] = int(b_dir) + 30000\n",
    "                    idx += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Failed to read images from Directory: ', b_dir)\n",
    "                print('Exception Message: ', e)\n",
    "                             \n",
    "        print('Dataset loaded successfully.')\n",
    "        return X,y    \n",
    "    def preprocessing(self):\n",
    "        X, y = self.read_dataset()\n",
    "\n",
    "        labels = list(set(y))\n",
    "        \n",
    "        # map random directory numbers to 0, 1, 2, ... n-1 and store the mapped labels in Y\n",
    "        label_dict = dict(zip(labels, range(len(labels))))\n",
    "        Y = np.asarray([label_dict[label] for label in y])        \n",
    "\n",
    "        # shuffle the images and labels (in the same order)\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "        x_shuffled = []\n",
    "        y_shuffled = []\n",
    "        \n",
    "        for index in shuffle_indices:\n",
    "            x_shuffled.append(X[index])\n",
    "            y_shuffled.append(Y[index])\n",
    "        \n",
    "        return np.asarray(x_shuffled), np.asarray(y_shuffled)\n",
    "\n",
    "    # (mal, mal, mal) triplet\n",
    "    def get_triplets(self):\n",
    "        # include only the malicious cluster labels (label 0 - 23)\n",
    "        exclude_benign = self.unique_train_label[:self.benign_anc_start]\n",
    "        \n",
    "        # label_l is the cluster label from which we choose 2 indices (of anchor & positive training images) from\n",
    "        # label_r is another cluster label from which we choose 1 index (of negative training image) from\n",
    "        label_l, label_r = np.random.choice(exclude_benign, 2, replace=False)\n",
    "        \n",
    "        # a = anchor, p = positive, n = negative index\n",
    "        a, p = np.random.choice(self.map_train_label_indices[label_l],2, replace=False)\n",
    "        n = np.random.choice(self.map_train_label_indices[label_r])\n",
    "        return a, p, n\n",
    "\n",
    "    # (mal, mal, benign) triplet\n",
    "    def get_benign_triplets_1(self):\n",
    "        # get a random malicious cluster label (from label 0 - 22)\n",
    "        label_l = np.random.choice(self.unique_train_label[:self.benign_anc_start])\n",
    "\n",
    "        # get a benign anchor image cluster label (from label 23 - 522)\n",
    "        label_r = np.random.choice(self.unique_train_label[self.benign_anc_start:self.benign_pos_start])\n",
    "        \n",
    "        a, p = np.random.choice(self.map_train_label_indices[label_l],2, replace=False)\n",
    "        n = np.random.choice(self.map_train_label_indices[label_r])\n",
    "        \n",
    "        return a, p, n\n",
    "    \n",
    "    # (benign, benign, mal) triplet\n",
    "    def get_benign_triplets_2(self):\n",
    "        # get a random anchor benign image cluster label (from label 23 - 522)\n",
    "        label_a = np.random.choice(self.unique_train_label[self.benign_anc_start:self.benign_pos_start])\n",
    "        # get a corresponding benign positive image cluster label (from label 523 - 1022)\n",
    "        label_p = label_a + DIR_SIZE\n",
    "        # get a malicious image cluster label (from label 0 - 22)\n",
    "        label_n = np.random.choice(self.unique_train_label[self.benign_anc_start])\n",
    "\n",
    "        a = np.random.choice(self.map_train_label_indices[label_a])\n",
    "        p = np.random.choice(self.map_train_label_indices[label_p])\n",
    "        n = np.random.choice(self.map_train_label_indices[label_n])\n",
    "        \n",
    "        return a, p, n        \n",
    "    \n",
    "    # (benign, benign, benign) triplet\n",
    "    def get_benign_triplets_3(self):\n",
    "        # get a random anchor benign image cluster label (from label 23 - 522)\n",
    "        label_a = np.random.choice(self.unique_train_label[self.benign_anc_start:self.benign_pos_start])\n",
    "        # get a corresponding benign positive image cluster label (from label 523 - 1022)\n",
    "        label_p = label_a + DIR_SIZE\n",
    "        # get a benign negative image cluster label (from label 1023)\n",
    "        label_n = self.unique_train_label[self.benign_neg_start]\n",
    "\n",
    "        a = np.random.choice(self.map_train_label_indices[label_a])\n",
    "        p = np.random.choice(self.map_train_label_indices[label_p])\n",
    "        n = np.random.choice(self.map_train_label_indices[label_n])\n",
    "        \n",
    "        return a, p, n\n",
    "\n",
    "    def get_triplets_batch(self):\n",
    "        idxs_a, idxs_p, idxs_n = [], [], []\n",
    "        \n",
    "        # generate 300 triplets per triplet combination (to prevent OOM)\n",
    "        # (mal, mal, mal) \n",
    "        for i in range(NUM_TRIPLETS):\n",
    "            a, p, n = self.get_triplets()\n",
    "            idxs_a.append(a)\n",
    "            idxs_p.append(p)\n",
    "            idxs_n.append(n)\n",
    "        \n",
    "        # (mal, mal, benign)\n",
    "        for _ in range(NUM_TRIPLETS):\n",
    "            a, p, n = self.get_benign_triplets_1()\n",
    "            idxs_a.append(a)\n",
    "            idxs_p.append(p)\n",
    "            idxs_n.append(n)\n",
    "            \n",
    "        # (benign, benign, mal)\n",
    "        for _ in range(NUM_TRIPLETS):\n",
    "            a, p, n = self.get_benign_triplets_2()\n",
    "            idxs_a.append(a)\n",
    "            idxs_p.append(p)\n",
    "            idxs_n.append(n)\n",
    "            \n",
    "        # (benign, benign, benign)\n",
    "        for _ in range(NUM_TRIPLETS):\n",
    "            a, p, n = self.get_benign_triplets_3()\n",
    "            idxs_a.append(a)\n",
    "            idxs_p.append(p)\n",
    "            idxs_n.append(n)\n",
    "            \n",
    "        # shuffling to prevent bias because val_dataset is later taken from the last 20% of the dataset\n",
    "        shuffle_indices = np.random.permutation(np.arange(NUM_TRIPLETS * 4))\n",
    "        a_shuffled = []\n",
    "        p_shuffled = []\n",
    "        n_shuffled = []\n",
    "        \n",
    "        for index in shuffle_indices:\n",
    "            a_shuffled.append(idxs_a[index])\n",
    "            p_shuffled.append(idxs_p[index])\n",
    "            n_shuffled.append(idxs_n[index])\n",
    "\n",
    "        anchor_dataset = tf.data.Dataset.from_tensor_slices(self.images_train[a_shuffled,:])\n",
    "        positive_dataset = tf.data.Dataset.from_tensor_slices(self.images_train[p_shuffled,:])\n",
    "        negative_dataset = tf.data.Dataset.from_tensor_slices(self.images_train[n_shuffled, :])\n",
    "\n",
    "        dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cde17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Dataset...\n",
      "Read directory:  alert\n",
      "Read directory:  button\n",
      "Read directory:  card\n",
      "Read directory:  checkbox_checked\n",
      "Read directory:  checkbox_unchecked\n",
      "Read directory:  chip\n",
      "Read directory:  data_table\n",
      "Read directory:  dropdown_menu\n",
      "Read directory:  floating_action_button\n",
      "Read directory:  grid_list\n",
      "Read directory:  image\n",
      "Read directory:  label\n",
      "Read directory:  menu\n",
      "Read directory:  radio_button_checked\n",
      "Read directory:  radio_button_unchecked\n",
      "Read directory:  slider\n",
      "Read directory:  switch_disabled\n",
      "Read directory:  switch_enabled\n",
      "Read directory:  text_area\n",
      "Read directory:  text_field\n",
      "Read directory:  tooltip\n",
      "Read benign negative directory:  alert\n",
      "Failed to read images from Directory:  alert\n",
      "Exception Message:  invalid literal for int() with base 10: 'alert'\n",
      "Read benign negative directory:  button\n",
      "Failed to read images from Directory:  button\n",
      "Exception Message:  invalid literal for int() with base 10: 'button'\n",
      "Read benign negative directory:  card\n",
      "Failed to read images from Directory:  card\n",
      "Exception Message:  invalid literal for int() with base 10: 'card'\n",
      "Read benign negative directory:  checkbox_checked\n",
      "Failed to read images from Directory:  checkbox_checked\n",
      "Exception Message:  invalid literal for int() with base 10: 'checkbox_checked'\n",
      "Read benign negative directory:  checkbox_unchecked\n",
      "Failed to read images from Directory:  checkbox_unchecked\n",
      "Exception Message:  invalid literal for int() with base 10: 'checkbox_unchecked'\n",
      "Read benign negative directory:  chip\n",
      "Failed to read images from Directory:  chip\n",
      "Exception Message:  invalid literal for int() with base 10: 'chip'\n",
      "Read benign negative directory:  data_table\n",
      "Failed to read images from Directory:  data_table\n",
      "Exception Message:  invalid literal for int() with base 10: 'data_table'\n",
      "Read benign negative directory:  dropdown_menu\n",
      "Failed to read images from Directory:  dropdown_menu\n",
      "Exception Message:  invalid literal for int() with base 10: 'dropdown_menu'\n",
      "Read benign negative directory:  floating_action_button\n",
      "Failed to read images from Directory:  floating_action_button\n",
      "Exception Message:  invalid literal for int() with base 10: 'floating_action_button'\n",
      "Read benign negative directory:  grid_list\n",
      "Failed to read images from Directory:  grid_list\n",
      "Exception Message:  invalid literal for int() with base 10: 'grid_list'\n",
      "Read benign negative directory:  image\n",
      "Failed to read images from Directory:  image\n",
      "Exception Message:  invalid literal for int() with base 10: 'image'\n",
      "Read benign negative directory:  label\n",
      "Failed to read images from Directory:  label\n",
      "Exception Message:  invalid literal for int() with base 10: 'label'\n",
      "Read benign negative directory:  menu\n",
      "Failed to read images from Directory:  menu\n",
      "Exception Message:  invalid literal for int() with base 10: 'menu'\n",
      "Read benign negative directory:  radio_button_checked\n",
      "Failed to read images from Directory:  radio_button_checked\n",
      "Exception Message:  invalid literal for int() with base 10: 'radio_button_checked'\n",
      "Read benign negative directory:  radio_button_unchecked\n",
      "Failed to read images from Directory:  radio_button_unchecked\n",
      "Exception Message:  invalid literal for int() with base 10: 'radio_button_unchecked'\n",
      "Read benign negative directory:  slider\n",
      "Failed to read images from Directory:  slider\n",
      "Exception Message:  invalid literal for int() with base 10: 'slider'\n",
      "Read benign negative directory:  switch_disabled\n",
      "Failed to read images from Directory:  switch_disabled\n",
      "Exception Message:  invalid literal for int() with base 10: 'switch_disabled'\n",
      "Read benign negative directory:  switch_enabled\n",
      "Failed to read images from Directory:  switch_enabled\n",
      "Exception Message:  invalid literal for int() with base 10: 'switch_enabled'\n",
      "Read benign negative directory:  text_area\n",
      "Failed to read images from Directory:  text_area\n",
      "Exception Message:  invalid literal for int() with base 10: 'text_area'\n",
      "Read benign negative directory:  text_field\n",
      "Failed to read images from Directory:  text_field\n",
      "Exception Message:  invalid literal for int() with base 10: 'text_field'\n",
      "Read benign negative directory:  tooltip\n",
      "Failed to read images from Directory:  tooltip\n",
      "Exception Message:  invalid literal for int() with base 10: 'tooltip'\n",
      "Dataset loaded successfully.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (30798,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPreProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/anchors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/positive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m, in \u001b[0;36mPreProcessing.__init__\u001b[1;34m(self, data_src, benign_anc_path, benign_pos_path, benign_neg_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenign_neg_path \u001b[38;5;241m=\u001b[39m benign_neg_path\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading the Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_train_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_train)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_train_label_indices \u001b[38;5;241m=\u001b[39m {label: np\u001b[38;5;241m.\u001b[39mflatnonzero(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_train \u001b[38;5;241m==\u001b[39m label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_train_label}\n",
      "Cell \u001b[1;32mIn[13], line 158\u001b[0m, in \u001b[0;36mPreProcessing.preprocessing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m     x_shuffled\u001b[38;5;241m.\u001b[39mappend(X[index])\n\u001b[0;32m    156\u001b[0m     y_shuffled\u001b[38;5;241m.\u001b[39mappend(Y[index])\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(x_shuffled), np\u001b[38;5;241m.\u001b[39masarray(y_shuffled)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (30798,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "dataset = PreProcessing('./data/train', \n",
    "                        './data/anchors', \n",
    "                        './data/positive', \n",
    "                        './data/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57e78bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_triplets_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# returns a zip dataset\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 230\u001b[0m, in \u001b[0;36mPreProcessing.get_triplets_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# (mal, mal, benign)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_TRIPLETS):\n\u001b[1;32m--> 230\u001b[0m     a, p, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_benign_triplets_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     idxs_a\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[0;32m    232\u001b[0m     idxs_p\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "Cell \u001b[1;32mIn[13], line 180\u001b[0m, in \u001b[0;36mPreProcessing.get_benign_triplets_1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m label_l \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_train_label[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbenign_anc_start])\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# get a benign anchor image cluster label (from label 23 - 522)\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m label_r \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_train_label\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenign_anc_start\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenign_pos_start\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m a, p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_train_label_indices[label_l],\u001b[38;5;241m2\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_train_label_indices[label_r])\n",
      "File \u001b[1;32mmtrand.pyx:934\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "data = dataset.get_triplets_batch() # returns a zip dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
